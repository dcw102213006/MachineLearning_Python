


from urllib.request import urlopen
import sys
import numpy as np
import pylab
import scipy.stats as stats


target_url=("https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data")
data=urlopen(target_url)

xList=[]
labels=[]

for line in data:
    
    row=bytes.decode(line).strip().split(",")
    xList.append(row)
    
    
nrow=len(xList)
ncol=len(xList[1])



type=[0]*3
colCounts=[]

#產生第3欄的統計摘要
col=3
colData=[]

for row in xList:
    colData.append(float(row[col]))
colArray=np.array(colData)
colMean=np.mean(colArray)
colsd=np.std(colArray)
sys.stdout.write("Mean="+"\t"+str(colMean)+"\t\t"+"Standard Deviation=" + "\t" +str(colsd)+"\n")



stats.probplot(colData,dist="norm",plot=pylab)
pylab.show()
    

# sys.stdout.write("Number of Rows of Data="+str(len(xList))+'\n')
# sys.stdout.write("Number of Columns of Data="+str(len(xList[1]))+'\n')
# print(xList)



# for col in range(ncol):
#     for row in xList:
#         try: 
#             a=float(row[col])

#             if isinstance(a,float):
#                 type[0]+=1
#         except ValueError:
            
#             if len(row[col])>0:
#                 type[1]+=1
#             else: type[2]+=1
#     colCounts.append(type)
#     type=[0]*3

# sys.stdout.write("Col#" + "\t\t"+"Number" +"\t\t" + "Strings" + "\t\t" + "Other\n")
# iCol=0
# for types in colCounts:
#     sys.stdout.write(str(iCol)+"\t\t" +str(types[0])+"\t\t"+str(types[1])+"\t\t"+str(types[2])+"\n")
#     iCol+=1
